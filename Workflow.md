# Midterm Workflow & Code Walkthrough
**Student Notebook:** `midterm_codes_2023200080.ipynb.ipynb`

æœ¬è¯´æ˜æ–‡æ¡£é€æ®µè§£æä½ çš„ Notebookï¼Œé€æ¡æ˜ å°„åˆ°ä½œä¸šè¦æ±‚ï¼ˆæ•°æ®â†’ç‰¹å¾å·¥ç¨‹â†’å»ºæ¨¡â†’è°ƒå‚â†’è¯„ä¼°â†’æäº¤ï¼‰ï¼Œå¹¶ç»™å‡ºæ”¹è¿›å»ºè®®ä¸é¿å…æ•°æ®æ³„æ¼çš„æ ¸æŸ¥è¦ç‚¹ã€‚

## 0) æ€»è§ˆ / Checklist å¯¹ç…§
- è¯»å–æ•°æ®ï¼šå·²å‘ç°ï¼ˆread_csv è°ƒç”¨ 2 æ¬¡, read_excel è°ƒç”¨ 0 æ¬¡ï¼‰
- å»é™¤æ³„æ¼ç‰¹å¾ï¼ˆå¦‚ç¤¾åŒºä»·ï¼‰ï¼šç–‘ä¼¼å·²å¤„ç†
- åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•ï¼šå·²ä½¿ç”¨ train_test_splitï¼Œrandom_state==111ï¼šæ˜¯
- ç‰¹å¾å·¥ç¨‹ï¼šlog(True) / å¤šé¡¹å¼(True) / äº¤äº’é¡¹(True) / åˆ†ç®±(True) / å“‘å˜é‡(False)
- ç‰¹å¾é€‰æ‹©ï¼šç›¸å…³æ€§(True) / VIF(False) / Lasso(True)
- å¼‚å¸¸å€¼å¤„ç†ï¼šIQR(True) / Z-score(False)
- çº¿æ€§æ¨¡å‹ï¼šOLS(True) / LASSO(True) / Ridge(True) / ElasticNet(True)
- è°ƒå‚ï¼šGridSearchCV(True)ï¼Œäº¤å‰éªŒè¯æŠ˜æ•°ï¼šæœªæ£€æµ‹åˆ°å›ºå®šæ•°
- æŒ‡æ ‡ï¼šMAE(True) / RMSE(True) / RÂ²(True)
- é¢„æµ‹å¯¼å‡ºï¼šæœ‰ï¼›æ–‡ä»¶åæ˜¯å¦ä¸º prediction.csvï¼šå¦/æœªæ£€æµ‹åˆ°

## 1) ä¾èµ–ä¸åº“å¯¼å…¥ï¼ˆImportsï¼‰
æ£€æµ‹åˆ°ä¸»è¦åº“ï¼š
chardet, d, matplotlib.pyplot, numpy, os, pandas, re, s, seaborn, warnings

## 2) æ•°æ®è¯»å–ä¸åŸºç¡€å¤„ç†
- `read_csv` å‚æ•°ç¤ºä¾‹ï¼ˆå…± 2 å¤„ï¼‰ï¼š
  1. `pd.read_csv(file_path, encoding=encoding, low_memory=False)`
  2. `pd.read_csv(file_path, encoding=encoding, low_memory=False)`

## 3) æ•°æ®æ³„æ¼æ£€æŸ¥ä¸å¤„ç†
- æ£€æµ‹åˆ°ä»¥ä¸‹ç–‘ä¼¼åˆ é™¤æ³„æ¼ç‰¹å¾çš„ä»£ç ç‰‡æ®µï¼ˆèŠ‚é€‰ï¼‰ï¼š
```python
_, edges = pd.qcut(df_feat['å»ºç­‘é¢ç§¯_æ•°å€¼'].dropna(), q=6, labels=False, retbins=True, duplicates='drop')
_, edges = pd.qcut(df_feat['æˆ¿é¾„'].dropna(), q=6, labels=False, retbins=True, duplicates='drop')
numeric_cols = numeric_cols.drop(target_col)
train_df = train_df.dropna(subset=[target_col])
train_df = train_df.dropna(subset=[target_col])
train_df = train_df.drop([target_col], axis=1)
```

## 4) è®­ç»ƒ/æµ‹è¯•é›†åˆ’åˆ†
- å‘ç° `train_test_split(...)` è°ƒç”¨ï¼Œéƒ¨åˆ†å‚æ•°ç‰‡æ®µå¦‚ä¸‹ï¼š
  1. `
                X_price_train, y_price_train, test_size=0.2, random_state=111,
                shuffle=True
            `
  2. `
                X_rent_train, y_rent_train, test_size=0.2, random_state=111,
                shuffle=True
            `
- æ˜¯å¦æ»¡è¶³ä½œä¸š **random_state==111**ï¼š**æ˜¯**ã€‚

## 5) ç‰¹å¾å·¥ç¨‹ï¼ˆåˆ›å»ºä¸ç¼–ç ï¼‰
- å·²æ£€æµ‹åˆ°ï¼šå¯¹åæ€å˜é‡åšå¯¹æ•°/å¯¹æ•°+1 å˜æ¢ï¼›`PolynomialFeatures` ç”Ÿæˆå¤šé¡¹å¼ä¸ï¼ˆå¯é€‰ï¼‰äº¤äº’é¡¹ï¼›æ˜¾ç¤ºåœ°æ„é€ äº¤äº’é¡¹ï¼›åˆ†ç®±ï¼ˆ`pd.cut`/`pd.qcut`/`KBinsDiscretizer`ï¼‰

## 6) ç‰¹å¾é€‰æ‹©ä¸å¤šé‡å…±çº¿æ€§
- å·²æ£€æµ‹åˆ°ï¼šåŸºäºç›¸å…³æ€§ç­›é€‰/çƒ­åŠ›å›¾ï¼›åˆ©ç”¨ Lasso æƒé‡ç¨€ç–æ€§åšç‰¹å¾é€‰æ‹©

## 7) å¼‚å¸¸å€¼æ£€æµ‹ä¸å¤„ç†
- å·²æ£€æµ‹åˆ°ï¼šIQR/åˆ†ä½æ•°æ³•
  æ³¨æ„ï¼šä»…åœ¨è®­ç»ƒé›†ä¸Šæ‹Ÿåˆé˜ˆå€¼ï¼Œå†åº”ç”¨åˆ°éªŒè¯/æµ‹è¯•é›†ï¼Œé¿å…æ³„æ¼ã€‚

## 8) çº¿æ€§å»ºæ¨¡ä¸è°ƒå‚
- å·²ä½¿ç”¨æ¨¡å‹ï¼šLinearRegression (OLS), Lasso, Ridge, Elastic Net
- æ˜¯å¦ä½¿ç”¨ `GridSearchCV`ï¼šæ˜¯ï¼›äº¤å‰éªŒè¯æŠ˜æ•°ï¼šæœªå›ºå®š/æœªæ£€æµ‹åˆ°
- æ¨¡å‹ `.fit(...)` è°ƒç”¨æ¬¡æ•°ï¼ˆç²—ç•¥ï¼‰ï¼š5

## 9) è¯„ä¼°æŒ‡æ ‡ä¸å±•ç¤º
- å·²è®¡ç®—çš„æŒ‡æ ‡ï¼šMAEï¼ˆä½œä¸šå¼ºåˆ¶ï¼‰, MSE/RMSE, RÂ²
- è¯·æŒ‰è¦æ±‚æŠ¥å‘Šï¼šIn-sample / Out-of-sample / **6 æŠ˜**äº¤å‰éªŒè¯ï¼›å¹¶ç»Ÿè®¡å»é™¤å¼‚å¸¸å€¼åçš„æ ·æœ¬é‡ã€‚

**Notebook è¾“å‡ºä¸­ä¸æŒ‡æ ‡ç›¸å…³çš„ç‰‡æ®µï¼ˆèŠ‚é€‰ï¼‰**ï¼š
```text
âœ… OLS_Enhanced: è®­ç»ƒMAE = 627,809.12, éªŒè¯MAE = 631,630.11
âœ… Ridge_Enhanced: è®­ç»ƒMAE = 946,987.50, éªŒè¯MAE = 931,591.82
âœ… Lasso_Enhanced: è®­ç»ƒMAE = 855,901.17, éªŒè¯MAE = 845,393.49
âœ… ElasticNet_Enhanced: è®­ç»ƒMAE = 856,609.34, éªŒè¯MAE = 846,269.26
ğŸ“Š éªŒè¯é›†MAE: 631,630.11
â­ Kaggleåˆ†æ•°: 0.0
âœ… OLS_Enhanced: è®­ç»ƒMAE = 188,083.96, éªŒè¯MAE = 192,153.43
âœ… Ridge_Enhanced: è®­ç»ƒMAE = 260,237.14, éªŒè¯MAE = 263,269.66
âœ… Lasso_Enhanced: è®­ç»ƒMAE = 250,001.04, éªŒè¯MAE = 252,931.33
âœ… ElasticNet_Enhanced: è®­ç»ƒMAE = 249,997.11, éªŒè¯MAE = 252,932.67
ğŸ“Š éªŒè¯é›†MAE: 192,153.43
â­ Kaggleåˆ†æ•°: 0.0
   éªŒè¯é›†MAE: 631,630.11
   Kaggleåˆ†æ•°: 0.0
   éªŒè¯é›†MAE: 192,153.43
   Kaggleåˆ†æ•°: 0.0
```

## 10) Kaggle æäº¤æµæ°´çº¿
- å·²å‘ç° `to_csv(...)` å¯¼å‡ºï¼›è¯·ç¡®ä¿æ–‡ä»¶åä¸º `prediction.csv` ä¸”åˆ—å/æ ¼å¼ç¬¦åˆæ¯”èµ›è¦æ±‚ã€‚

## 11) æ•°æ®æ³„æ¼é£é™©æ§åˆ¶ï¼ˆå¼ºåˆ¶ï¼‰
- **æ‰€æœ‰**é¢„å¤„ç†ï¼ˆæ ‡å‡†åŒ–ã€åˆ†ç®±è¾¹ç•Œã€ç¼–ç å™¨ã€PCA/å¤šé¡¹å¼ã€ç‰¹å¾é€‰æ‹©é˜ˆå€¼ç­‰ï¼‰é¡»æ”¾å…¥ `Pipeline` / `ColumnTransformer` å¹¶ä»…åŸºäºè®­ç»ƒé›†æ‹Ÿåˆã€‚
- ä½ å·²ç»æ˜¾å¼åˆ é™¤äº†ç–‘ä¼¼æ³„æ¼åˆ—ï¼›è¯·ç»§ç»­æ£€æŸ¥æ˜¯å¦å­˜åœ¨åŸºäºç›®æ ‡çš„èšåˆç»Ÿè®¡æˆ–æ—¶é—´ç©¿è¶Šã€‚

## 12) ä¸è¶³ä¸å¯æ”¹è¿›ç‚¹ï¼ˆæ¸…å•ï¼‰
1. å°†äº¤å‰éªŒè¯æŠ˜æ•°ç»Ÿä¸€è®¾ä¸º `cv=6`ã€‚
2. å¯¹ç±»åˆ«å˜é‡è¿›è¡Œ one-hot ç¼–ç å¹¶ä¿æŒåˆ—å¯¹é½ã€‚
3. è®¡ç®— VIF å¹¶å‰”é™¤é«˜å…±çº¿ç‰¹å¾ï¼ˆé˜ˆå€¼ 5~10ï¼‰ã€‚
4. å¯¼å‡º `prediction.csv` å¹¶éµå¾ª Git/Kaggle æäº¤è§„èŒƒã€‚

## 13) éšæœºç§å­ä¸æ¨¡å‹ä¸€è§ˆ
- å‡ºç°è¿‡çš„ `random_state` å€¼ï¼š[111]
- æ¨¡å‹è¦†ç›–ï¼šOLS, LASSO, Ridge, ElasticNet

## é™„ï¼šæ— æ³„æ¼ Pipeline + GridSearchCV æ¨¡æ¿ï¼ˆå¯ç›´æ¥æ”¹é€ ï¼‰
```python

from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import OneHotEncoder, StandardScaler, PolynomialFeatures
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet
from sklearn.model_selection import GridSearchCV, train_test_split
from sklearn.metrics import mean_absolute_error
import numpy as np

num_cols = [...]   # æ•°å€¼åˆ—
cat_cols = [...]   # ç±»åˆ«åˆ—

num_pipe = Pipeline([
    ("scale", StandardScaler()),
    ("poly", PolynomialFeatures(degree=2, include_bias=False))
])

cat_pipe = Pipeline([
    ("onehot", OneHotEncoder(handle_unknown="ignore"))
])

pre = ColumnTransformer([
    ("num", num_pipe, num_cols),
    ("cat", cat_pipe, cat_cols)
])

models = {
    "OLS": LinearRegression(),
    "Ridge": Ridge(),
    "Lasso": Lasso(max_iter=10000),
    "ElasticNet": ElasticNet(max_iter=10000),
}

param_grid = {
    "Ridge": {
        "pre__num__poly__degree": [1, 2],
        "model__alpha": [0.1, 1.0, 10.0]
    },
    "Lasso": {
        "pre__num__poly__degree": [1, 2],
        "model__alpha": [0.0001, 0.001, 0.01, 0.1]
    },
    "ElasticNet": {
        "pre__num__poly__degree": [1, 2],
        "model__alpha": [0.001, 0.01, 0.1, 1.0],
        "model__l1_ratio": [0.2, 0.5, 0.8]
    }
}

# å•æ¨¡å‹ç¤ºä¾‹ï¼ˆRidgeï¼‰
pipe = Pipeline([("pre", pre), ("model", models["Ridge"])])

gcv = GridSearchCV(
    estimator=pipe,
    param_grid=param_grid["Ridge"],
    scoring="neg_mean_absolute_error",
    cv=6,
    n_jobs=-1
)

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=111)
gcv.fit(X_train, y_train)

y_pred_tr = gcv.predict(X_train)
y_pred_te = gcv.predict(X_test)
print("MAE in-sample:", mean_absolute_error(y_train, y_pred_tr))
print("MAE out-of-sample:", mean_absolute_error(y_test, y_pred_te))
print("Best params:", gcv.best_params_)

# Kaggle å¯¼å‡ºï¼ˆç¤ºæ„ï¼‰
# sub = pd.DataFrame({'Id': test_id, 'price': gcv.predict(X_test_like_competition)})
# sub.to_csv('prediction.csv', index=False)

```